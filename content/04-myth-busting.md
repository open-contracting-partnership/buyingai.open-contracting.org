# GenAI adoption myth-busting 

| Who: Procurement, project, and leadership teams What: Myths around planning, technical capacity, integration, and governance, and the reality  |
| :---- |

## GenAI adoption myths

As procurement officials play an increasingly critical role in their organizations' AI adoption journeys, it's important to separate fact from fiction. While GenAI offers transformative potential, successful procurement requires a clear understanding of technical realities, vendor capabilities, and implementation challenges.

This section addresses common misconceptions about GenAI procurement and adoption. We break down popular myths, explain the reality, and highlight key considerations when evaluating vendors. Understanding these nuances will help procurement officials make more informed decisions and set realistic expectations. 

### Planning myths

**Myth: "Implementing GenAI is always cost-effective and provides immediate ROI."**   
**Reality: GenAI projects can require significant upfront investment and ongoing costs. ROI may take time to realize and depend on proper implementation and use.** Some tasks could be accomplished equally well by non-GenAI technology. During vendor evaluation, look for tools for cost estimation, ROI projection, and optimization to help make informed decisions and maximize the value of AI investments.

**Myth: "AI systems are set-and-forget solutions."**   
**Reality: AI systems require continuous updates, retraining, monitoring, and testing.**   
During vendor evaluation, consider end-to-end tools for AI lifecycle management (MLOps) to ensure models stay effective, fair, and compliant over time. 

### Technical capacity myths

**Myth: "One GenAI model can solve all tasks effectively."**   
**Reality: Large language models are foundational, but fine-tuning, prompt engineering, and guardrails are critical to make them useful and safe in specific contexts.** Different models may be optimal for different use cases and considerations, such as cost, latency or built-in safeguards and bias mitigation. Look for vendors that have the capability to help adapt foundation models to unique needs, embedding safeguards and improving accuracy for specific use cases. 

**Myth: "Complete transparency of AI systems is always possible and necessary."**   
**Reality: While transparency is important, its meaning and implementation can vary.** Transparency in GenAI can encompass:

* Technical transparency: Understanding of model architecture and training data  
* Operational transparency: Clear communication about AI system capabilities and limitations  
* User transparency: Informing users when they are interacting with AI-enabled systems

When considering vendors, look for clear documentation on model purpose, inputs, known limitations, and responsible use cases tailored to public sector needs, commitment to user transparency, such as clear labeling of AI-generated content or interactions, regular updates on model changes and improvements and willingness to discuss the balance between proprietary technology and transparency needs. Remember: Full technical transparency of large models isn't always feasible or meaningful to non-technical users. Focus on transparency that enhances trust, supports responsible use, and aligns with your organization's needs and values.

**Myth: "AI decisions can always be explained in simple terms."**   
**Realty: Not all AI decisions can be explained like a rulebook — context matters.**  Seek out vendors with support for guardrails that meet the requirements for explainability /interpretability of the specific use case, which may include human-in-the-loop design.

### Integration myths 

**Myth: “AI systems from different vendors can easily work together.”**  
**Reality: True interoperability doesn't mean every model works with every system out of the box.** During vendor evaluation, look for vendors that support open standards, APIs, and modular architectures that allow AI tools to integrate into existing IT environments and minimize rework when switching providers. Clear data processing and storage polices and transparent terms regarding ownership of customizations and prompts. Remember: As solutions improve through usage and customization, the accumulated knowledge in refined prompts and optimizations becomes valuable intellectual property. Understanding ownership and portability of these improvements is crucial for long-term vendor flexibility.

**Myth: "AI models and data can be easily transferred between systems."**   
**Reality: You can move the data, but models may need reconfiguration or even retraining when moved to new environments.** This is due to differences in hardware, software frameworks, and system architectures. Look for vendors that have support for standard model formats and container technologies, structured export options and data export/import tools, standard data format support, multi-cloud and cross-platform capabilities and assistance with planning migration strategies that minimize friction. 

**Myth: "All GenAI systems and tools can easily work together and share data."**  
**Reality: Different GenAI systems often speak different languages \- from varying API structures and data formats to different security protocols and performance standards.** Making systems work together requires significant integration effort, standardization, and often custom middleware solutions. Seek vendors that support industry standards and common API, pre-built connectors for popular platforms, clear documentation of integration requirements, flexible authentication and security options, commitment to backwards compatibility, integration testing and validation tools.

**Myth: “Once I start with one provider, I'm stuck forever.”**   
**Realty: Lock-in is not binary. It's about cost and effort to switch, not impossibility.** Look for vendors that have data available for export for example including prompts or effort you put in initially to customize/calibrate, open-source model formats, containerization options   
(e.g., Docker, Kubernetes), and hybrid/multicloud support to enable transitions when needed. 

### Governance myths 

**Myth: "AI implementation must be risk-free."**   
**Reality: The goal is not zero risk — it's understood, mitigated, and monitored risk.** During vendor evaluation, look for support for responsible AI frameworks, sandboxing environments, and robust logging to help assess and manage risks realistically. 

**Myth: "Open source AI is always safer, cheaper, or better."**   
**Reality: Open source in GenAI can refer to different components (model architecture, weights, or training code).** While it offers benefits like transparency and flexibility, open source does not mean no cost, or no risk. Responsibility, security, and support still matter. During vendor evaluation, look for clear explanations of which components are open source versus proprietary, support for major open-source frameworks (e.g., Hugging Face, ONNX, PyTorch), secure, scalable environments for deployment, defined processes for updates and security patches, clear support and maintenance agreements, documentation of compliance and security measures, transparent cost structure including all operational aspects and expertise in both open-source and enterprise implementation.

**Myth: “Open-source AI is always more risky and unsafe.”**  
**Reality: Open source is not inherantly more or risky or unsafe than proprietary GenAI.** The context matters a lot. It depends upon which components are developed using open source, your use case, and the extent to which you need active technical support and frequent updates.  

**Myth: "Data must never leave the country to ensure sovereignty."**   
**Reality: It's not just about geography. It’s often more important to understand who has access, how it's encrypted, and who controls keys.** During vendor evaluation, consider local hosting options and sovereign environments when needed, customer-managed encryption keys, and compliance tooling to meet residency and sovereignty needs in context. 

